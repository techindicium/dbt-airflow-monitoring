name: CI

on:
  pull_request:
    types:
      - opened
      - synchronize
    branches:
      - main   

env:
    DBT_PROFILES_DIR: ${{ github.workspace }}
    DBT_DEFAULT_TARGET: databricks
    DEV_CATALOG_NAME: cdi_dev
    DEV_SCHEMA_NAME: ci_dbt_dag_monitoring
    DEV_HOST: ${{ secrets.DATABRICKS_HOST }}
    DEV_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
    DEV_HTTP_PATH: ${{ secrets.HTTP_PATH }}


jobs:
  dbt-checks:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run dbt debug
        run: dbt debug

      - name: dbt deps
        run: dbt deps

      - name: dbt compile
        run: dbt compile

  integration-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.8'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: enter integration tests
        run: |
          cd integration_tests/

      - name: Authenticate to GCP
        uses: "google-github-actions/auth@v2"
        with:
          credentials_json: "${{ secrets.BIGQUERY_AUTH }}"
      
      # - name: Run dbt integration tests
      #   env:
      #     DBT_PROFILES_DIR: ${{ github.workspace }}/integration_tests
      #     DBT_PROJECT_DIR: ${{ github.workspace }}/integration_tests
      #   run: |
      #     dbt deps 

      #     dbt seed --target databricks
          
      #     dbt run-operation jobs --target databricks
      #     dbt run-operation job_runs --target databricks
          
      #     dbt test -s source:* --target databricks
          
      #     dbt build --target databricks

      # - name: switch enabled sources for adf source
      #   run: |
      #     cd ${{ github.workspace }}
      #     . change_dbt_project_adf_source.sh
      #     cd integration_tests/

      # - name: Run dbt tasks for adf source
      #   env:
      #     DBT_PROFILES_DIR: ${{ github.workspace }}/integration_tests
      #     DBT_PROJECT_DIR: ${{ github.workspace }}/integration_tests
      #   run: |
      #     dbt deps

      #     dbt seed --target databricks

      #     dbt run-operation adf_pipeline_runs --target databricks
      #     dbt run-operation adf_triggers --target databricks

      #     dbt test -s source:* --target databricks

      #     dbt build --target databricks

      # - name: switch enabled sources for airflow source
      #   run: |
      #     cd ${{ github.workspace }}
      #     . change_dbt_project_airflow_source.sh
      #     cd integration_tests/

      # - name: Run dbt tasks for airflow source
      #   env:
      #     DBT_PROFILES_DIR: ${{ github.workspace }}/integration_tests
      #     DBT_PROJECT_DIR: ${{ github.workspace }}/integration_tests
      #   run: |
      #     dbt deps

      #     dbt seed --target databricks

      #     dbt test -s source:* --target databricks

      #     dbt build --target databricks

      #     dbt run-operation drop_schema --args '{schema_name: ci_dbt_dag_monitoring}'


